{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from spacy.en import English\n",
    "from spacy.symbols import ORTH, LEMMA, POS, SYM, TAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = English()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "94",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bd8508d28814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m parser.tokenizer.add_special_case('||',\n\u001b[0;32m----> 2\u001b[0;31m                                   [{\"F\":'||', \"L\":'Paragraph_Break', \"pos\":'PUNCT'}])\n\u001b[0m",
      "\u001b[0;32m/Users/ophidian/anaconda/envs/py35/lib/python3.5/site-packages/spacy/tokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.add_special_case (spacy/tokenizer.cpp:7621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/ophidian/anaconda/envs/py35/lib/python3.5/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.make_fused_token (spacy/vocab.cpp:6415)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/ophidian/anaconda/envs/py35/lib/python3.5/site-packages/spacy/morphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.assign_tag (spacy/morphology.cpp:3918)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 94"
     ]
    }
   ],
   "source": [
    "parser.tokenizer.add_special_case('||',\n",
    "                                  [{\"F\":'||', \"L\":'Paragraph_Break', \"pos\":'PUNCT'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizer special case example:\n",
    "```python\n",
    "parser.tokenizer.add_special_case(u'gimme',\n",
    "    [\n",
    "        {\n",
    "            ORTH: u'gim',\n",
    "            LEMMA: u'give',\n",
    "            POS: u'VERB'},\n",
    "        {\n",
    "            ORTH: u'me'}])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excerpt = '\"Mr. Marley has been dead these seven years,\" Scrooge replied. \"He died seven years ago, this very night.\" || \"We have no doubt his liberality is well represented by his surviving partner,\" said the gentleman, presenting his credentials. || It certainly was; for they had been two kindred spirits. At the ominous word \"liberality\" Scrooge frowned, and shook his head, and handed the credentials back. || \"At this festive season of the year, Mr. Scrooge,\" said the gentleman, taking up a pen, \"it is more than usually desirable that we should make some slight provision for the poor and destitute, who suffer greatly at the present time. Many thousands are in want of common necessaries; hundreds of thousands are in want of common comforts, sir.\" || \"Are there no prisons?\" asked Scrooge. || \"Plenty of prisons,\" said the gentleman, laying down the pen again. || \"And the Union workhouses?\" demanded Scrooge. \"Are they still in operation?\" || \"They are. Still,\" returned the gentleman, \"I wish I could say they were not.\" || \"The Treadmill and the Poor Law are in full vigour, then?\" said Scrooge. || \"Both very busy, sir.\" || \"Oh! I was afraid, from what you said at first, that something had occurred to stop them in their useful course,\" said Scrooge. \"I am very glad to hear it.\"'\n",
    "print(excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsedData = parser(excerpt)\n",
    "\n",
    "sentences = [sent.string.strip() for sent in parsedData.sents]\n",
    "\n",
    "for s in sentences:\n",
    "    print(s, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_lower = [tok.lower_ for tok in parser(excerpt)]\n",
    "# print(token_lower)\n",
    "token_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
